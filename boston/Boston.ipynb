{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Boston.csv\")\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kroki postepowania:\n",
    "\n",
    "1. Dzielimy zbiór na treningowy i testowy\n",
    "2. Na zbiorze treningowym uczymy model regresji zmiennej lstat do medv\n",
    "3. Wyliczamy na zbiorze testowym predykcje i na ich podstawie porównując do wartości rzeczywisych wyliczamy MSE\n",
    "4. Na zbiorze treningowym stosujemy GridSearchCV, który odpowie nam na pytanie który stopień wielomianu jest najlepszy\n",
    "5. Na zbiorze treningowym uczymy model wielomianu odpowiedniego stopnia \n",
    "6. Na zbiorze testowym sprawdzamy MSE tego modelu jak w przypadku modelu zwykłej prostej regresji\n",
    "7. Porówujemy oba wyniki i wskazujemy lepszy model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.lstat.values.reshape(-1,1)\n",
    "y = df.medv.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = model_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred_lr)\n",
    "print('MSE: ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_regress_pipeline = make_pipeline(PolynomialFeatures(), LinearRegression())\n",
    "\n",
    "random_search = GridSearchCV(poly_regress_pipeline, {\n",
    "    'polynomialfeatures__degree': range(1, 10)\n",
    "}, cv=3, verbose=1)\n",
    "\n",
    "random_search.fit(X_train.reshape(-1,1), y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model  = make_pipeline(PolynomialFeatures(5), LinearRegression()).fit(X_test.reshape(-1,1), y_test)\n",
    "y_pred_grid = best_model.predict(X_test.reshape(-1,1))\n",
    "y_test.shape, y_pred_grid.shape, y_pred_lr.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_grid = mean_squared_error(y_test, y_pred_grid)\n",
    "mse_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykresy\n",
    "\n",
    "plt.scatter(X_test, y_test, facecolors='None', edgecolors='k', alpha=.7) \n",
    "sns.regplot(X_test, y_pred_lr, ci=None, label='Linear', scatter=False, color='grey')\n",
    "sns.regplot(X_test, y_pred_grid, ci=None, label='Polynomial', order=5, scatter=False, color='pink')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE przy zastosowaniu regresji liniowej wyniosl:', mse)\n",
    "print('MSE po zastosowaniu GridSearchCV wyniosl:', mse_grid)\n",
    "print('Lepszy jest model po zastosowaniu GridSearchCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
